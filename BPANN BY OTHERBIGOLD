
# coding: utf-8

# In[1]:


'''
需要import的库
'''
import numpy as np
from matplotlib import pyplot
from scipy import optimize


# In[2]:


'''
首先调用BPprocess得到Theta1和Theta2，
再调用getAccuracy获取正确率;
训练一次后，可以将Theta1和Theta2保存到文件里,
载入训练好的权值,
然后直接调用getAccuracy获取正确率即可;
注意Theta1和Theta2两个权值矩阵的尺寸:
Theta1.shape(hidden_layer_size,input_layer_size)
Theta2.shape(output_layer_size,hidden_layer_size)
'''


# In[3]:


def readData(filePath):
    return np.loadtxt(filePath)


# In[4]:


def BPprocess(X,y,input_layer_size,hidden_layer_size,num_labels = 1,lambda_=0.0,maxiter=200):
    '''
    参数
    ----
    X：m*n样本数据矩阵，m是样本数，n是特征维度数
    y：标签向量
    input_layer_size：输入层神经数量——n(X的列数)
    hidden_layer_size：隐藏层神经元数量——自定义
    num_labels:输出层神经元数量——默认为一（二分类）
    lambda_：正则化参数——默认为0（不正则化）
    maxiter：优化迭代次数——默认200
    
    返回值
    ------
    Theta1：输入层到中间层的参数矩阵
    Theta2：中间层到输出层的参数矩阵
    '''
    #初始化theta1，theta2，options（迭代次数）
    initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)
    initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)
    initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)
    options = {'maxiter': maxiter}
    
    costFunction = lambda p: nnCostFunction(p, input_layer_size,
                                        hidden_layer_size,
                                        num_labels, X, y, lambda_)
    # 优化方法默认BFGS
    res = optimize.minimize(costFunction,
                        initial_nn_params,
                        jac=True,
                        method='TNC',
                        options=options)
    
    nn_params = res.x
    
    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],
                    (hidden_layer_size, (input_layer_size + 1)))

    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],
                    (num_labels, (hidden_layer_size + 1)))
    
    return Theta1,Theta2


# In[5]:


def getAccuracy(Theta1,Theta2,X,y,threshold = 0.5):
    '''
    参数
    ----
    Theta1：输入层到中间层的第一个权值矩阵
    Theta2：中间层到输出层的第二个权值矩阵
    X：数据矩阵
    y：数据对应的标签矩阵
    threshold：阈值，默认为0.5，用来作为决策依据
    
    返回值
    ------
    pred：对每个数据的预测结果矩阵(0或1)，pred.shape = (m,)
    '''
    pred = predict(Theta1, Theta2, X,y,threshold)
    x = 0
#     for i in range(pred.size):
#         if pred[i] == y[i]:
#             x += 1
#     print(x)
    print('This Set Accuracy: {:.1f}%'.format(np.mean(pred == y) * 100))
    return pred


# In[6]:


def predict(Theta1, Theta2, X,y,threshold = 0.5):
    '''
    阈值默认0.5
    '''
    if X.ndim == 1:
        X = X[None]#将一维的X提升到二维
        
    m = X.shape[0]
    p = np.zeros(m)
    num_labels = Theta2.shape[0]
    
    a2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis = 1),Theta1.T))
    a3 = sigmoid(np.dot(np.concatenate([np.ones((m,1)),a2],axis = 1),Theta2.T))
    # a2.shape = (m,hidden_layer_size)
    # a3.shape = (m,output_layer_size)(每个样本的输出神经元的值)
    # p.shape = (m,)(样本的预测值)
    
    
    # 二分类
    p = a3
    #print(p)
    #print(p)
    p[p>threshold] = 1
    p[p<=threshold] = 0
    
    return p


# In[7]:


def sigmoid(z):
    """
    Computes the sigmoid of z.
    """
    return 1.0 / (1.0 + np.exp(-z))
# 可以计算矩阵，也可以计算标量


# In[8]:


def sigmoidGradient(z):
    return np.multiply(sigmoid(z),(1.0 - sigmoid(z)))
# 可以计算矩阵，也可以计算标量


# In[9]:


def randInitializeWeights(L_in, L_out, epsilon_init=0.12):
    W = epsilon_init * (np.random.rand(L_out,L_in+1) * 2 - 1)
    # generate random number in [-epsilon_init,epsilon_init) 
    # with shape of L_out*(L_in+1)
    return W


# In[10]:


def forwardPass(Theta1,Theta2,X):
    if X.ndim == 1:
        X = X[None]#将一维的X提升到二维
        
    m = X.shape[0]
    num_labels = Theta2.shape[0]
    
    z2 = np.dot(np.concatenate([np.ones((m, 1)), X], axis = 1),Theta1.T)
    a2 = sigmoid(z2)
    z3 = np.dot(np.concatenate([np.ones((m,1)),a2],axis = 1),Theta2.T)
    a3 = sigmoid(z3)
    
    #print(z2.shape)#(5000,25)
    #print(a2.shape)#(5000,25)
    #print(z3.shape)#(5000,25)
    #print(a3.shape)#(5000,10)
    # return the activation values and z values of hidden layer and output layer
    # for BP training
    return z2,a2,z3,a3


# In[11]:


def nnCostFunction(nn_params,#将Theta1和Theta2统一起来
                   input_layer_size,
                   hidden_layer_size,
                   num_labels,
                   X,
                   y,
                   lambda_=0.0):
    
    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],
                        (hidden_layer_size, (input_layer_size + 1)))
    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],
                        (num_labels, (hidden_layer_size + 1)))

    # Setup some useful variables
    m = y.size
    z2,a2,z3,h = forwardPass(Theta1, Theta2, X)     
    
    # Theta1_grad & Theta2_grad is the gradient of Theta
    J = 0
    Theta1_grad = np.zeros(Theta1.shape)
    Theta2_grad = np.zeros(Theta2.shape)
    
    # transform y to logic array
#     temp = np.zeros((m,num_labels))
#     for i in range(m): 
#         temp[i][y[i]] = 1
#     y = temp# y.shape = (m,num_laybels)
    
    # compute J
    for i in range(m):
        J += np.dot(np.log(h[i]),y[i]) + np.dot(np.log(1-h[i]),(1-y[i]))
    J /= (-m)
    J += (lambda_/(2*m))*(np.sum(Theta2[:,1:]**2)+np.sum(Theta1[:,1:]**2))#正则化J

    # compute grad
    delta3 = h - y
    # delta3.shape = (5000,10)

    delta2 = np.dot(delta3,Theta2) 
    delta2 = delta2[:,1:]
    delta2 = np.multiply(delta2,sigmoidGradient(z2))
    #delta2.shape = (5000,25)
    
    a1 = np.concatenate([np.ones((m, 1)), X], axis = 1) #a1.shape = (5000,401)
    a2 = np.concatenate([np.ones((m,1)),a2],axis = 1)#a2.shape = (5000,26)
    Theta1_grad = np.dot(delta2.T,a1) / m
    Theta2_grad = np.dot(delta3.T,a2) / m
    # Theta1.shape = (25,401)
    # Theta2.shape = (10,26)
    Theta1_grad[:,1:] += (lambda_/m) * Theta1[:,1:]
    Theta2_grad[:,1:] += (lambda_/m) * Theta2[:,1:]
    
    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])

    return J, grad


# In[12]:


hidden_layer_size = 100
input_layer_size = 74
num_labels = 1
clusters = 4

path_alltrain = 'E:\\temp\\program\\python\\聚类\\train1.txt'
path_alltest = 'E:\\temp\\program\\python\\聚类\\test1.txt'
X = readData(path_alltrain)
print(X.shape)
y = np.array(X[:,-1:],dtype = np.uint8)
X = X[:,:input_layer_size]
Theta1,Theta2 = BPprocess(X,y,X.shape[1],hidden_layer_size,lambda_= 0,maxiter= 2000)
# #     print(i)
pred = getAccuracy(Theta1,Theta2,X,y,threshold = 0.5)

X_test = readData(path_alltest)
y_test = np.array(X_test[:,-1:],dtype = np.uint8)
X_test = X_test[:,:input_layer_size]
pred = getAccuracy(Theta1,Theta2,X_test,y_test,threshold = 0.5)
print(pred)
# lambda_ = np.zeros(4)
# path_train = [[] for i in range(clusters)]
# path_test = [[] for i in range(clusters)]
# path_train[0] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\train1.txt'
# path_train[1] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\train2.txt'
# path_train[2] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\train3.txt'
# path_train[3] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\train4.txt'
# path_test[0] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\test1.txt'
# path_test[1] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\test1.txt'
# path_test[2] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\test1.txt'
# path_test[3] = 'C:\\Users\\39410\\Desktop\\大创项目\\BPNetwork\\test1.txt'
# X1 = readData(path1)
# y1 = np.array(X1[:,-1:],dtype=np.uint8)

# Theta1 = np.zeros((clusters,hidden_layer_size,input_layer_size+1))
# Theta2 = np.zeros((clusters,num_labels,hidden_layer_size+1))
# # print(Theta1.shape)
# # print(Theta2.shape)
# lambda_[0] = 39
# lambda_[1] = 27
# lambda_[2] = 30
# lambda_[3] = 38

# for i in range(100):
#     X = readData(path_train[2])
#     y = np.array(X[:,-1:],dtype = np.uint8)
#     X = X[:,:input_layer_size]
#     Theta1,Theta2 = BPprocess(X,y,X.shape[1],hidden_layer_size,lambda_=i)
#     print(i)
#     getAccuracy(Theta1,Theta2,X,y)

# for i in range(clusters):
#     X_train = readData(path_train[i])
#     y_train = np.array(X_train[:,-1:],dtype = np.uint8)
#     X_train = X_train[:,:input_layer_size]
#     Theta1[i],Theta2[i] = BPprocess(X_train,y_train,X_train.shape[1],hidden_layer_size,lambda_ = lambda_[i])
#     print("This set shape = ",X_train.shape)
#     getAccuracy(Theta1[i],Theta2[i],X_train,y_train)
    
# print("\n\nfollow is the test set")
# for i in range(clusters):
#     X_test = readData(path_test[i])
#     y_test = np.array(X_test[:,-1:],dtype = np.uint8)
#     X_test = X_test[:,:input_layer_size]
#     print("This set shape = ",X_test.shape)
#     getAccuracy(Theta1[i],Theta2[i],X_test,y_test)



#%%
